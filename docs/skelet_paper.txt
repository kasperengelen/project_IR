paper IR:

structuur DB van lucene:
    lucene heeft een index
    de index bestaat uit segmenten
    een segment bestaat uit een doc (elk met een doc id dat uniek in aan segment, maar niet over de segmenten heen)
    een doc bestaat uit fields

    Lucene heeft ook een in-memory buffer. Deze kan geflushed worden naar een on-disk segment.

    Lucene gebruikt een inverted index. Maar hier zijn ook uitbreidingen aan. Zo kan met datastructuren opstellen
    om de index te "uninverten", dit is evt nuttig voor performance van sorteren.

Constructie van een index:
    men maakt Document objecten aan en voegt er fields aan toe. Daarna gebruikt men een IndexWriter om documenten aan de index toe te voegen
    d.m.v. addDocument of updateDocument

    Waaruit een document bestaat, of waarde data van een document vandaankomt is vrij te kiezen voor de gebruiker. De gebruiker kan ervoor kiezen
    om bijv een file te openen, en onderdelen ervan toe te voegen aan een document.

Fields:
    Fields kunnen "gestored" worden. Dit betekent dat ze letterlijk worden opgeslagen in het geheugen, zodat ze later kant en klaar gepresenteerd kunnen worden
    aan de gebruiker tijdens een query.
    Fields "geindexeerd" worden. Dit betekent dat ze in queries gebruikt kunnen worden als zoekterm.
    
    Er is ook een tokenization en analyzing capabilities voor fields. Dit houdt in dat fields opgesplitst worden in tokens, tokens gefilterd worden, spelling correctie, etc.
    Er is ook een termVector. Dit is alle informatie over die term zoals frequencies. Je kan het zien als een per-document inverted index.
    Fields hebben ook bepaalde normalisation functionaliteiten waardoor de relevantie van termen kan worden opgeslagen in een term.
    Ook multidimensional data is mogelijk.

    TextField vs StringField: Text is tokenized en niet gestored, String is niet tokenized en is stored.

Bruikbaarheid voor de stackoverflow dataset:
    Zeer bruikbaar. Elke XML kan toegevoegd worden als een document. We moeten nog kijken hoe performant Lucene is met 3 miljoen documenten.

Querying:
    Lucene heeft faciliteiten voor quering, met inbegrip van een querying taal. Het queryen houdt in dat met een IndexSearcher object aanmaakt, en deze een query aanrijkt.
    Een query kan opgesteld worden door ze neer te schrijven in een String en ze te parser met QueryParser. Na het searchen kan men de top-k resultaten retrieven, alsook de bijhorende scores.

Analyzing:
    Een analyzer bestaat uit een Tokenizer en een Filter. Meerdere bestaande tokenizers en filters kunnen aangeen geschakeld worden. Het is mogelijk om voor elke Field van een document een andere analyzer te voorzien.
    Analyzers voeren taken uit zoals een string opsplitsen in tokens, irrelevante tokens (zoals stopwoorden) filteren, alles naar lowercase zetten, etc.
    Custom tokenizers zijn mogelijk. Een tokenizer wordt aan de indexer en querier gegeven.
    Er worden ook taal-specifieke analyzers voorzien. English analyzer voorziet het inkorten van woorden naar de stam, conversie naar lowercase, etc.
    Sommige analyzers herkennen bepaalde partronen zoals emailadressen en URL's.    

Sources:
    https://www.alibabacloud.com/blog/analysis-of-lucene---basic-concepts_594672
    http://makble.com/lucene-field-stringfield-vs-textfield
    https://www.baeldung.com/lucene-analyzers


